---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Greetings, I am Le Zhang, a Ph.D student at the [Mila - Quebec AI Institute](https://mila.quebec/en/person/le-zhang/).  Currently, I‚Äôm working with Prof. [Aishwarya Agrawal](https://www.iro.umontreal.ca/~agrawal/) in the domain of vision-language learning. Perviously, I obtained Bachelor degree from Fudan University. Besides, I worked with Prof Zhongyu Wei and I conducted a summer research with Prof. Diyi Yang, and interned at Shanghai AI Lab with Dr. Siqi Sun.

# Reaserach Interests

My research primarily centers around the domains of computer vision and multimodal learning. 

# News and Updates üéâ

------
- [Mar 2025] üåü One paper SAIL got accepted at ***CVPR 2024 Highlight*** [*project*](https://lezhang7.github.io/sail.github.io/)

- [Sep 2024] üéØ Two papers accepted at ***NeurIPS 2024***:
  - MSA augmentation for protein structure prediction with language models
  - Visual minimal-change understanding for vision-language models

- [Sep 2024] üìö One paper on Information Retrieval with Large Language Models accepted to ***EMNLP 2024 Findings***

- [May 2024] üîç One paper on Graph Convolution and Contrastive Learning accepted to ***KDD 2024***

- [Feb 2024] üñºÔ∏è One paper on vision-language compositional understanding accepted to ***CVPR 2024***

- [Dec 2023] üí° One paper on zero-shot multimodal question answering accepted to ***EMNLP 2023 Findings***

- [Sep 2023] üéì Started graduate study at Mila!

- [Feb-Sep 2022] üíº Research Intern at Shanghai AI Lab

- [May 2022] üìù Two papers accepted at ***NAACL 2022***

# Publications

------
- **Assessing and Learning Alignment of Unimodal Vision and Language Models (SAIL)**  
  **Le Zhang**, <span style="color:gray;">Qian Yang, Aishwarya Agrawal</span>  
  *CVPR 2024 Highlight* [[*project*](https://lezhang7.github.io/sail.github.io/)]

- **Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence Alignment Generation**  
  **Le Zhang**, <span style="color:gray;">Jiayang Chen, Tao Shen, Yu Li, Siqi Sun.</span>   
  *NeurIPS 2024* [[*arxiv*](https://arxiv.org/abs/2306.01824) | [*code*](https://github.com/lezhang7/MSA-Augmentor)]
- **VisMin: Visual Minimal-Change Understanding**  
  <span style="color:gray;">Rabiul Awal\*, Saba Ahmadi\*,</span> **Le Zhang**\*, <span style="color:gray;">Aishwarya Agrawal</span>  
  *NeurIPS 2024* [*project*](https://rabiul.me/vismin/)
- **Exploring the Best Practices of Query Expansion with Large Language Models**  
  **Le Zhang**, <span style="color:gray;">Qian Yang, Yihong Wu.</span>   
  *EMNLP 2024 findings* [[*arxiv*](https://arxiv.org/abs/2401.06311) | [*code*](https://github.com/lezhang7/Retrieval_MuGI)]
- **Unifying Graph Convolution and Contrastive Learning in Collaborative Filtering**  
  <span style="color:gray;">Yihong Wu</span>, **Le Zhang**, <span style="color:gray;">Fengran Mo, Tianyu Zhu, Weizhi Ma, Jian-Yun Nie</span>  
  *KDD 2024*
- **Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding**  
  **Le Zhang**, <span style="color:gray;">Rabiul Awal, Aishwarya Agrawal</span>  
  *CVPR 2024* [[*arXiv*](https://arxiv.org/abs/2306.08832) | [*code*](https://github.com/lezhang7/Enhance-FineGrained)]
- **MoqaGPT: Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model**  
  **Le Zhang**, <span style="color:gray;">Yihong Wu, Fengran Mo, Jian-Yun Nie, Aishwarya Agrawal.</span>  
   *EMNLP 2023 Findings* [[*arxiv*](https://arxiv.org/abs/2310.13265) | [*code*](https://github.com/lezhang7/MOQAGPT)]
- **Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering**  
  <span style="color:gray;">Rabiul Awal,</span> **Le Zhang**, <span style="color:gray;">Aishwarya Agrawal.</span>  
   *CVPR2024W Oral* [[*arxiv*](https://arxiv.org/abs/2306.09996)]

- SUBS: Subtree Substitution for Compositional Semantic Parsing  
  <span style="color:gray;">Jingfeng Yang\*,</span> **Le Zhang**\*, <span style="color:gray;">Diyi Yang.</span>   
  *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.01538) | [*code*](https://github.com/SALT-NLP/SUBS)]
- **TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding**  
  **Le Zhang**, <span style="color:gray;">Zichao Yang, Diyi Yang.</span>   
  *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.06153) | [*code*](https://github.com/lezhang7/TreeMix)]

# Services

------

- Conference Reviewer: ***ACL 2023***, ***EMNLP 2023***, ***CVPR 2024***, ***ARR 2024 Feb, Apr, June***, ***ECCV 2024***,  ***Neurips 2024***
- Teaching Assistant: [IFT 6765 - Links between Computer Vision and Language](https://sites.google.com/mila.quebec/ift6765-h2024/course-description)