---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Greetings, I am Le Zhang, a Ph.D student at the [Mila - Quebec AI Institute](https://mila.quebec/en/person/le-zhang/).  Currently, Iâ€™m working with Prof. [Aishwarya Agrawal](https://www.iro.umontreal.ca/~agrawal/) in the domain of vision-language learning. Perviously, I obtained Bachelor degree from Fudan University. Besides, I worked with Prof Zhongyu Wei and I conducted a summer research with Prof. Diyi Yang, and interned at Shanghai AI Lab with Dr. Siqi Sun.

# Reaserach Interests

My research primarily centers around the domains of visual intelligence and vision-language learning. Presently, visual representations exhibit complexity and intermingling. Conversely, human perception apprehends the world by organizing objects or visual concepts as fundamental units, known as an object-centric approach. Moreover, humans tend to segment objects prior to recognizing their labels. Therefore, my current research endeavors involve **developing a novel visual modeling methodology that can autonomously segment objects and acquire object-centric representations in an unsupervised manner**. Subsequently, I aim to establish connections between this architecture and language to construct a robust model endowed with compositional understanding capabilities.

# News and Updates
======

- Our paper for zero-shot multimodal question answering got accepted into EMNLP2023 findings
- One [paper](https://arxiv.org/abs/2306.08832) on fine-grained understanding has been selected as CVPR 2023 [O-DRUM workshop](https://asu-apg.github.io/odrum/) highlight!
- Start graduate study at Mila!
- Interned at Shanghai AI Lab from 2022/02-2022/09
- Two paper got accepted at NAACL 2022!

# Publications

======

- MuGI: Enhancing Information Retrieval through Multi-Text Generation Intergration with Large Language Models
  **Le Zhang**, Qian Yang, Yihong Wu. *arXiv preprint arXiv:2401.06311* [[*arxiv*](https://arxiv.org/abs/2401.06311)|[*code*](https://github.com/lezhang7/Retrieval_MuGI)]

- MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model
  **Le Zhang**, Yihong Wu, Fengran Mo, Jian-Yun Nie, Aishwarya Agrawal. *EMNLP2023 Findings* [[*arxiv*](https://arxiv.org/abs/2310.13265)|[*code*](https://github.com/lezhang7/MOQAGPT)]
  
- Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Fine-grained Understanding
  **Le Zhang**, Rabiul Awal, Aishwarya Agrawal
  *CVPR O-DRUM@2023 workshop Highlight* [[*arxiv*](https://arxiv.org/abs/2306.08832)|[*code*](https://github.com/lezhang7/Enhance-FineGrained)]

- Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering
  Rabiul Awal, **Le Zhang**, Aishwarya Agrawal. *arXiv preprint arXiv:2306.09996* [[*arxiv*](https://arxiv.org/abs/2306.09996)]
  
- Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence Alignment Generation
  **Le Zhang**\*, Jiayang Chen\*, Tao Shen, Yu Li, Siqi Sun. *arXiv preprint arXiv:2306.01824* [[*arxiv*](https://arxiv.org/abs/2306.01824)|[*code*](https://github.com/lezhang7/MSA-Augmentor)]
  
- SUBS: Subtree Substitution for Compositional Semantic Parsing
  Jingfeng Yang\*, **Le Zhang**\*, Diyi Yang. *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.01538)|[*code*](https://github.com/SALT-NLP/SUBS)]
  
- TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding
  **Le Zhang**, Zichao Yang, Diyi Yang. *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.06153)|[*code*](https://github.com/lezhang7/TreeMix)]

# Services
------

- Reviewer of ACL 2023, EMNLP 2023, CVPR 2024, ARR Feb 2024, ECCV 2024
