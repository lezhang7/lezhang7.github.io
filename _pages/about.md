---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Greetings, I am Le Zhang, a Ph.D student at the [Mila - Quebec AI Institute](https://mila.quebec/en/person/le-zhang/).  Currently, Iâ€™m working with Prof. [Aishwarya Agrawal](https://www.iro.umontreal.ca/~agrawal/) in the domain of vision-language learning. Perviously, I obtained Bachelor degree from Fudan University. Besides, I worked with Prof Zhongyu Wei and I conducted a summer research with Prof. Diyi Yang, and interned at Shanghai AI Lab with Dr. Siqi Sun.

# Reaserach Interests

My research primarily centers around the domains of computer vision and multimodal learning. 

# News and Updates

------

- <font color=red>**[Feb 2024]**</font>One paper on vision-language compositional understanding has been accepted to ***CVPR 2024***
- One paper for zero-shot multimodal question answering got accepted into ***EMNLP2023 findings***
- Start graduate study at Mila!
- Interned at Shanghai AI Lab from 2022/02-2022/09
- Two paper got accepted at ***NAACL 2022*** 

# Publications

------

- **Contrasting Intra-Modal and Ranking Cross-Modal Hard Negatives to Enhance Visio-Linguistic Compositional Understanding**  
  Le Zhang, <span style="color:gray;">Rabiul Awal, Aishwarya Agrawal</span>  
  *CVPR 2024* [[*arXiv*](https://arxiv.org/abs/2306.08832) | [*code*](https://github.com/lezhang7/Enhance-FineGrained)]
- **MuGI: Enhancing Information Retrieval through Multi-Text Generation Integration with Large Language Models**  
  **Le Zhang**, <span style="color:gray;">Qian Yang, Yihong Wu.</span>   
  *arXiv preprint arXiv:2401.06311* [[*arxiv*](https://arxiv.org/abs/2401.06311) | [*code*](https://github.com/lezhang7/Retrieval_MuGI)]
- **MoqaGPT: Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model**  
  **Le Zhang**, <span style="color:gray;">Yihong Wu, Fengran Mo, Jian-Yun Nie, Aishwarya Agrawal.</span>  
   *EMNLP 2023 Findings* [[*arxiv*](https://arxiv.org/abs/2310.13265) | [*code*](https://github.com/lezhang7/MOQAGPT)]
- **Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering**  
  <span style="color:gray;">Rabiul Awal,</span> **Le Zhang**, <span style="color:gray;">Aishwarya Agrawal.</span>  
   *arXiv preprint arXiv:2306.09996* [[*arxiv*](https://arxiv.org/abs/2306.09996)]
- **Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence Alignment Generation**  
  **Le Zhang**\*, <span style="color:gray;">Jiayang Chen\*, Tao Shen, Yu Li, Siqi Sun.</span>   
  *arXiv preprint arXiv:2306.01824* [[*arxiv*](https://arxiv.org/abs/2306.01824) | [*code*](https://github.com/lezhang7/MSA-Augmentor)]
- SUBS: Subtree Substitution for Compositional Semantic Parsing  
  <span style="color:gray;">Jingfeng Yang\*,</span> **Le Zhang**\*, <span style="color:gray;">Diyi Yang.</span>   
  *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.01538) | [*code*](https://github.com/SALT-NLP/SUBS)]
- **TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding**  
  **Le Zhang**, <span style="color:gray;">Zichao Yang, Diyi Yang.</span>   
  *NAACL 2022* [[*arxiv*](https://arxiv.org/abs/2205.06153) | [*code*](https://github.com/lezhang7/TreeMix)]

# Services

------

- Conference Reviewer: ***ACL 2023***, ***EMNLP 2023***, ***CVPR 2024***, ***ARR Feb 2024***, ***ECCV 2024***
- Teaching Assistant: [IFT 6765 - Links between Computer Vision and Language](https://sites.google.com/mila.quebec/ift6765-h2024/course-description)